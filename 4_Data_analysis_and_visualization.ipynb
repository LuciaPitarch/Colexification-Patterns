{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4. Data_analysis_and_visualization.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPF/8JMiYyK8MbVp/0xMYnW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LuciaPitarch/Colexification-Patterns/blob/main/4_Data_analysis_and_visualization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODL4wUdiIM6Z"
      },
      "source": [
        "This codes takes the CLICS3 colexification data as base and explores the diachronical patterns of colexification in romance and polynesian languages. \n",
        "\n",
        "This file is both in Python and R. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "413KmUq-Hhxl"
      },
      "source": [
        "# 0. LOAD LIBRARIES AND DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgPMp4-PIDyP"
      },
      "source": [
        "#import libraries\n",
        "import pandas\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GH_5erdELDTP",
        "outputId": "7fc5cc2c-c123-4c6a-a1f3-e41904f5c97b"
      },
      "source": [
        "#download data\n",
        "!gdown --id 1AgNMJq7hhuL2hsxrj5hGEDKfrTsNUPAF #polynesian features\n",
        "!gdown --id 1xlmO2gnPnncoLjfO8-_qYm_EVAg4KSVF #romance features"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1AgNMJq7hhuL2hsxrj5hGEDKfrTsNUPAF\n",
            "To: /content/polynesian_df_features.csv\n",
            "100% 317k/317k [00:00<00:00, 46.3MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1xlmO2gnPnncoLjfO8-_qYm_EVAg4KSVF\n",
            "To: /content/romance_df_features.csv\n",
            "100% 348k/348k [00:00<00:00, 49.8MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oM2sip-3Xy2U"
      },
      "source": [
        "#load the data\n",
        "polynesian_df = pandas.read_csv('polynesian_df_features.csv')\n",
        "romance_df = pandas.read_csv('romance_df_features.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVMVKuO-X1ny"
      },
      "source": [
        "#merge polynesian and romance df into a single one\n",
        "df = pandas.concat([polynesian_df, romance_df])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QgM6_hmHmDU"
      },
      "source": [
        "# 1. DATA OVERVIEW"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IS4FiWZ1K-zj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1db11433-7db6-4c8f-e9de-24f0a463148f"
      },
      "source": [
        "#data summary\n",
        "print(df.count())\n",
        "print(polynesian_df.groupby('maintained').size())\n",
        "print(romance_df.groupby('maintained').size())\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unnamed: 0                3653\n",
            "Form.x                    1829\n",
            "clics_form                1829\n",
            "Glottocode                1829\n",
            "Concepticon_ID.x          1829\n",
            "Concepticon_Gloss.x       3653\n",
            "Family                    1829\n",
            "variety                   1829\n",
            "Ontological_Category.x    1829\n",
            "Semantic_Field.x          1829\n",
            "Form.y                    1829\n",
            "Concepticon_ID.y          1829\n",
            "Concepticon_Gloss.y       3653\n",
            "Ontological_Category.y    1829\n",
            "Semantic_Field.y          1829\n",
            "pairs                     3653\n",
            "maintained                1829\n",
            "phonetic_pairs            1829\n",
            "colexifies                3653\n",
            "cosine_sim                2742\n",
            "n_char                    1829\n",
            "pos.x                     3387\n",
            "pos.y                     3355\n",
            "pos_pairs                 3120\n",
            "pos_same                  3120\n",
            "path_pairs                2678\n",
            "wup_pairs                 2678\n",
            "Semantic_pairs            3653\n",
            "Ontological_pairs         3653\n",
            "dtype: int64\n",
            "maintained\n",
            "0.0    594\n",
            "1.0    286\n",
            "dtype: int64\n",
            "maintained\n",
            "0.0    333\n",
            "1.0    616\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Form.x</th>\n",
              "      <th>clics_form</th>\n",
              "      <th>Glottocode</th>\n",
              "      <th>Concepticon_ID.x</th>\n",
              "      <th>Concepticon_Gloss.x</th>\n",
              "      <th>Family</th>\n",
              "      <th>variety</th>\n",
              "      <th>Ontological_Category.x</th>\n",
              "      <th>Semantic_Field.x</th>\n",
              "      <th>Form.y</th>\n",
              "      <th>Concepticon_ID.y</th>\n",
              "      <th>Concepticon_Gloss.y</th>\n",
              "      <th>Ontological_Category.y</th>\n",
              "      <th>Semantic_Field.y</th>\n",
              "      <th>pairs</th>\n",
              "      <th>maintained</th>\n",
              "      <th>phonetic_pairs</th>\n",
              "      <th>colexifies</th>\n",
              "      <th>cosine_sim</th>\n",
              "      <th>n_char</th>\n",
              "      <th>pos.x</th>\n",
              "      <th>pos.y</th>\n",
              "      <th>pos_pairs</th>\n",
              "      <th>pos_same</th>\n",
              "      <th>path_pairs</th>\n",
              "      <th>wup_pairs</th>\n",
              "      <th>Semantic_pairs</th>\n",
              "      <th>Ontological_pairs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>187</td>\n",
              "      <td>*nuku</td>\n",
              "      <td>nuku</td>\n",
              "      <td>poly1242</td>\n",
              "      <td>626.0</td>\n",
              "      <td>land</td>\n",
              "      <td>Austronesian</td>\n",
              "      <td>Proto Polynesian</td>\n",
              "      <td>Person/Thing</td>\n",
              "      <td>The physical world</td>\n",
              "      <td>*nuku</td>\n",
              "      <td>2023.0</td>\n",
              "      <td>crowd</td>\n",
              "      <td>Person/Thing</td>\n",
              "      <td>Quantity</td>\n",
              "      <td>('land', 'crowd')</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.084035</td>\n",
              "      <td>4.0</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>('n', 'n')</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.307692</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>210</td>\n",
              "      <td>*refu</td>\n",
              "      <td>refu</td>\n",
              "      <td>poly1242</td>\n",
              "      <td>2.0</td>\n",
              "      <td>dust</td>\n",
              "      <td>Austronesian</td>\n",
              "      <td>Proto Polynesian</td>\n",
              "      <td>Person/Thing</td>\n",
              "      <td>The physical world</td>\n",
              "      <td>*refu</td>\n",
              "      <td>646.0</td>\n",
              "      <td>ash</td>\n",
              "      <td>Person/Thing</td>\n",
              "      <td>The physical world</td>\n",
              "      <td>('dust', 'ash')</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.460755</td>\n",
              "      <td>4.0</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>('n', 'n')</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.125397</td>\n",
              "      <td>0.476035</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>211</td>\n",
              "      <td>*lefu</td>\n",
              "      <td>lefu</td>\n",
              "      <td>poly1242</td>\n",
              "      <td>2.0</td>\n",
              "      <td>dust</td>\n",
              "      <td>Austronesian</td>\n",
              "      <td>Proto Polynesian</td>\n",
              "      <td>Person/Thing</td>\n",
              "      <td>The physical world</td>\n",
              "      <td>*lefu</td>\n",
              "      <td>1843.0</td>\n",
              "      <td>thousand</td>\n",
              "      <td>Number</td>\n",
              "      <td>Quantity</td>\n",
              "      <td>('dust', 'thousand')</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.124580</td>\n",
              "      <td>4.0</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>('n', 'n')</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.076923</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>218</td>\n",
              "      <td>*qoru</td>\n",
              "      <td>qoru</td>\n",
              "      <td>poly1242</td>\n",
              "      <td>640.0</td>\n",
              "      <td>mud</td>\n",
              "      <td>Austronesian</td>\n",
              "      <td>Proto Polynesian</td>\n",
              "      <td>Person/Thing</td>\n",
              "      <td>The physical world</td>\n",
              "      <td>*qoru</td>\n",
              "      <td>1145.0</td>\n",
              "      <td>swamp</td>\n",
              "      <td>Person/Thing</td>\n",
              "      <td>The physical world</td>\n",
              "      <td>('mud', 'swamp')</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.407885</td>\n",
              "      <td>4.0</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>('n', 'n')</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.081169</td>\n",
              "      <td>0.260504</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>219</td>\n",
              "      <td>*pela</td>\n",
              "      <td>pela</td>\n",
              "      <td>poly1242</td>\n",
              "      <td>640.0</td>\n",
              "      <td>mud</td>\n",
              "      <td>Austronesian</td>\n",
              "      <td>Proto Polynesian</td>\n",
              "      <td>Person/Thing</td>\n",
              "      <td>The physical world</td>\n",
              "      <td>*pela</td>\n",
              "      <td>1558.0</td>\n",
              "      <td>similar</td>\n",
              "      <td>Property</td>\n",
              "      <td>Spatial relations</td>\n",
              "      <td>('mud', 'similar')</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.001168</td>\n",
              "      <td>4.0</td>\n",
              "      <td>n</td>\n",
              "      <td>a</td>\n",
              "      <td>('n', 'a')</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1891</th>\n",
              "      <td>942</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>side</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>fowl</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>('side', 'fowl')</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0.064977</td>\n",
              "      <td>NaN</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>('n', 'n')</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.088462</td>\n",
              "      <td>0.320513</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1892</th>\n",
              "      <td>943</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>swamp</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>lagoon</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>('swamp', 'lagoon')</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0.410354</td>\n",
              "      <td>NaN</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>('n', 'n')</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1893</th>\n",
              "      <td>944</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>fishing line</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>barley</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>('fishing line', 'barley')</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>n</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1894</th>\n",
              "      <td>945</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>towel</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>rag</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>('towel', 'rag')</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0.432502</td>\n",
              "      <td>NaN</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>('n', 'n')</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.129936</td>\n",
              "      <td>0.335935</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1895</th>\n",
              "      <td>946</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>storm</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>fishhook</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>('storm', 'fishhook')</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>('n', 'n')</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.235294</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3653 rows × 29 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Unnamed: 0 Form.x  ... Semantic_pairs Ontological_pairs\n",
              "0            187  *nuku  ...              0                 1\n",
              "1            210  *refu  ...              1                 1\n",
              "2            211  *lefu  ...              0                 0\n",
              "3            218  *qoru  ...              1                 1\n",
              "4            219  *pela  ...              0                 0\n",
              "...          ...    ...  ...            ...               ...\n",
              "1891         942    NaN  ...              0                 0\n",
              "1892         943    NaN  ...              0                 0\n",
              "1893         944    NaN  ...              0                 0\n",
              "1894         945    NaN  ...              0                 0\n",
              "1895         946    NaN  ...              0                 0\n",
              "\n",
              "[3653 rows x 29 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4Y9KSzqdiOC"
      },
      "source": [
        "%load_ext rpy2.ipython"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vnDoMhRbnzn",
        "outputId": "e21297b1-2ff4-48f7-aff1-dfd876c6c9d3"
      },
      "source": [
        "%%R # to run R on colab\n",
        "\n",
        "library(dplyr)\n",
        "library(readr)\n",
        "library(tidyr)\n",
        "\n",
        "polynesian_df <- read_csv('polynesian_df_features.csv')\n",
        "romance_df <- read_csv('romance_df_features.csv')\n",
        "df <- merge(romance_df, polynesian_df, all.x=T, all.y=T)\n",
        "\n",
        "#set categorical data\n",
        "cat_cols <- c('maintained', 'colexifies', 'pos_pairs', 'pos_same', \n",
        "              'Semantic_pairs', 'Ontological_pairs', 'Family')\n",
        "df[,cat_cols] <- lapply(df[,cat_cols], as.factor)\n",
        "\n",
        "#data overview\n",
        "print(summary(df))\n",
        "str(df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "── Column specification ────────────────────────────────────────────────────────\n",
            "cols(\n",
            "  .default = col_character(),\n",
            "  X1 = col_double(),\n",
            "  Concepticon_ID.x = col_double(),\n",
            "  Concepticon_ID.y = col_double(),\n",
            "  maintained = col_double(),\n",
            "  phonetic_pairs = col_double(),\n",
            "  colexifies = col_double(),\n",
            "  cosine_sim = col_double(),\n",
            "  n_char = col_double(),\n",
            "  pos_same = col_double(),\n",
            "  path_pairs = col_double(),\n",
            "  wup_pairs = col_double(),\n",
            "  Semantic_pairs = col_double(),\n",
            "  Ontological_pairs = col_double()\n",
            ")\n",
            "ℹ Use `spec()` for the full column specifications.\n",
            "\n",
            "\n",
            "── Column specification ────────────────────────────────────────────────────────\n",
            "cols(\n",
            "  .default = col_character(),\n",
            "  X1 = col_double(),\n",
            "  Concepticon_ID.x = col_double(),\n",
            "  Concepticon_ID.y = col_double(),\n",
            "  maintained = col_double(),\n",
            "  phonetic_pairs = col_double(),\n",
            "  colexifies = col_double(),\n",
            "  cosine_sim = col_double(),\n",
            "  n_char = col_double(),\n",
            "  pos_same = col_double(),\n",
            "  path_pairs = col_double(),\n",
            "  wup_pairs = col_double(),\n",
            "  Semantic_pairs = col_double(),\n",
            "  Ontological_pairs = col_double()\n",
            ")\n",
            "ℹ Use `spec()` for the full column specifications.\n",
            "\n",
            "       X1            Form.x           clics_form         Glottocode       \n",
            " Min.   :   0.0   Length:3653        Length:3653        Length:3653       \n",
            " 1st Qu.: 314.0   Class :character   Class :character   Class :character  \n",
            " Median : 610.0   Mode  :character   Mode  :character   Mode  :character  \n",
            " Mean   : 852.9                                                           \n",
            " 3rd Qu.:1074.0                                                           \n",
            " Max.   :4021.0                                                           \n",
            "                                                                          \n",
            " Concepticon_ID.x Concepticon_Gloss.x           Family       variety         \n",
            " Min.   :   2     Length:3653         Austronesian : 880   Length:3653       \n",
            " 1st Qu.: 702     Class :character    Indo-European: 949   Class :character  \n",
            " Median :1176     Mode  :character    NA's         :1824   Mode  :character  \n",
            " Mean   :1143                                                                \n",
            " 3rd Qu.:1495                                                                \n",
            " Max.   :3458                                                                \n",
            " NA's   :1824                                                                \n",
            " Ontological_Category.x Semantic_Field.x      Form.y          Concepticon_ID.y\n",
            " Length:3653            Length:3653        Length:3653        Min.   :   7    \n",
            " Class :character       Class :character   Class :character   1st Qu.: 711    \n",
            " Mode  :character       Mode  :character   Mode  :character   Median :1235    \n",
            "                                                              Mean   :1214    \n",
            "                                                              3rd Qu.:1644    \n",
            "                                                              Max.   :3464    \n",
            "                                                              NA's   :1824    \n",
            " Concepticon_Gloss.y Ontological_Category.y Semantic_Field.y  \n",
            " Length:3653         Length:3653            Length:3653       \n",
            " Class :character    Class :character       Class :character  \n",
            " Mode  :character    Mode  :character       Mode  :character  \n",
            "                                                              \n",
            "                                                              \n",
            "                                                              \n",
            "                                                              \n",
            "    pairs           maintained  phonetic_pairs   colexifies   cosine_sim     \n",
            " Length:3653        0   : 927   Min.   : 0.000   0:1824     Min.   :-0.1398  \n",
            " Class :character   1   : 902   1st Qu.: 0.000   1:1829     1st Qu.: 0.0734  \n",
            " Mode  :character   NA's:1824   Median : 1.000              Median : 0.1411  \n",
            "                                Mean   : 1.045              Mean   : 0.2001  \n",
            "                                3rd Qu.: 1.000              3rd Qu.: 0.3148  \n",
            "                                Max.   :10.000              Max.   : 0.8610  \n",
            "                                NA's   :1824                NA's   :911      \n",
            "     n_char          pos.x              pos.y                pos_pairs   \n",
            " Min.   : 1.000   Length:3653        Length:3653        ('n', 'n'):2436  \n",
            " 1st Qu.: 4.000   Class :character   Class :character   ('v', 'n'): 200  \n",
            " Median : 5.000   Mode  :character   Mode  :character   ('n', 'v'): 157  \n",
            " Mean   : 4.833                                         ('n', 'a'):  92  \n",
            " 3rd Qu.: 6.000                                         ('a', 'n'):  66  \n",
            " Max.   :14.000                                         (Other)   : 169  \n",
            " NA's   :1824                                           NA's      : 533  \n",
            " pos_same      path_pairs       wup_pairs      Semantic_pairs Ontological_pairs\n",
            " 0   : 653   Min.   :0.0410   Min.   :0.0787   0:2834         0:2345           \n",
            " 1   :2467   1st Qu.:0.0712   1st Qu.:0.1891   1: 819         1:1308           \n",
            " NA's: 533   Median :0.0833   Median :0.2555                                   \n",
            "             Mean   :0.1051   Mean   :0.3044                                   \n",
            "             3rd Qu.:0.1111   3rd Qu.:0.3681                                   \n",
            "             Max.   :1.0000   Max.   :1.0000                                   \n",
            "             NA's   :975      NA's   :975                                      \n",
            "'data.frame':\t3653 obs. of  29 variables:\n",
            " $ X1                    : num  0 0 1 1 2 2 2 3 3 3 ...\n",
            " $ Form.x                : chr  NA NA NA NA ...\n",
            " $ clics_form            : chr  NA NA NA NA ...\n",
            " $ Glottocode            : chr  NA NA NA NA ...\n",
            " $ Concepticon_ID.x      : num  NA NA NA NA 674 NA NA 674 NA NA ...\n",
            " $ Concepticon_Gloss.x   : chr  \"calf\" \"look for\" \"person\" \"testicles\" ...\n",
            " $ Family                : Factor w/ 2 levels \"Austronesian\",..: NA NA NA NA 2 NA NA 2 NA NA ...\n",
            " $ variety               : chr  NA NA NA NA ...\n",
            " $ Ontological_Category.x: chr  NA NA NA NA ...\n",
            " $ Semantic_Field.x      : chr  NA NA NA NA ...\n",
            " $ Form.y                : chr  NA NA NA NA ...\n",
            " $ Concepticon_ID.y      : num  NA NA NA NA 1394 ...\n",
            " $ Concepticon_Gloss.y   : chr  \"navel\" \"bay\" \"betray\" \"see\" ...\n",
            " $ Ontological_Category.y: chr  NA NA NA NA ...\n",
            " $ Semantic_Field.y      : chr  NA NA NA NA ...\n",
            " $ pairs                 : chr  \"('calf', 'navel')\" \"('look for', 'bay')\" \"('person', 'betray')\" \"('testicles', 'see')\" ...\n",
            " $ maintained            : Factor w/ 2 levels \"0\",\"1\": NA NA NA NA 1 NA NA 1 NA NA ...\n",
            " $ phonetic_pairs        : num  NA NA NA NA 1 NA NA 1 NA NA ...\n",
            " $ colexifies            : Factor w/ 2 levels \"0\",\"1\": 1 1 1 1 2 1 1 2 1 1 ...\n",
            " $ cosine_sim            : num  0.2298 NA 0.0902 NA 0.2482 ...\n",
            " $ n_char                : num  NA NA NA NA 2 NA NA 2 NA NA ...\n",
            " $ pos.x                 : chr  \"n\" NA \"n\" \"n\" ...\n",
            " $ pos.y                 : chr  \"n\" \"n\" \"v\" \"n\" ...\n",
            " $ pos_pairs             : Factor w/ 21 levels \"('a', 'a')\",\"('a', 'n')\",..: 6 NA 9 6 6 6 9 6 6 6 ...\n",
            " $ pos_same              : Factor w/ 2 levels \"0\",\"1\": 2 NA 1 2 2 2 1 2 2 2 ...\n",
            " $ path_pairs            : num  0.0871 NA NA 0.0667 0.0757 ...\n",
            " $ wup_pairs             : num  0.364 NA NA 0.222 0.289 ...\n",
            " $ Semantic_pairs        : Factor w/ 2 levels \"0\",\"1\": 1 1 1 1 2 1 1 2 1 1 ...\n",
            " $ Ontological_pairs     : Factor w/ 2 levels \"0\",\"1\": 1 1 1 1 2 1 1 2 1 1 ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rk-86ugyHu2X"
      },
      "source": [
        "# 2. QUANTITATIVE ANALYSIS: LOGISTIC REGRESSION MODELS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnLxmnVdHzs2"
      },
      "source": [
        " 2.1. Which features predict diachronic patterns of colexification (which colexifications are loss/maintained)? \n",
        "\n",
        "To run this model we select just the attested colexifications as data. Then we run different logistic regression models to analyse which features better predict the loss and maintanace of colexifications. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8K-Ua6jF00X"
      },
      "source": [
        "%%R\n",
        "#logreg model\n",
        "#model1:all features, loss/maintained\n",
        "\n",
        "m1 <- glm(data=df[df$colexifies ==1, ], \n",
        "          maintained ~ phonetic_pairs+cosine_sim +n_char+pos_same+path_pairs+wup_pairs+ \n",
        "          Semantic_pairs+Ontological_pairs,\n",
        "          family='binomial')\n",
        "summary(m1)\n",
        "#models for individual features, loss/maintained\n",
        "\n",
        "m2 <- glm(data=df[df$colexifies ==1, ], \n",
        "          maintained ~ phonetic_pairs, \n",
        "          family='binomial')\n",
        "\n",
        "\n",
        "m3 <- glm(data=df[df$colexifies ==1, ], \n",
        "          maintained ~ cosine_sim, \n",
        "          family='binomial')\n",
        "\n",
        "m4 <- glm(data=df[df$colexifies ==1, ], \n",
        "          maintained ~ n_char, \n",
        "          family='binomial')\n",
        "\n",
        "m5 <- glm(data=df[df$colexifies ==1, ], \n",
        "          maintained ~ pos_same, \n",
        "          family='binomial')\n",
        "\n",
        "m6 <- glm(data=df[df$colexifies ==1, ], \n",
        "          maintained ~ path_pairs, \n",
        "          family='binomial')\n",
        "\n",
        "m7 <- glm(data=df[df$colexifies ==1, ], \n",
        "          maintained ~ wup_pairs, \n",
        "          family='binomial')\n",
        "\n",
        "m8 <- glm(data=df[df$colexifies ==1, ], \n",
        "          maintained ~ Semantic_pairs, \n",
        "          family='binomial')\n",
        "\n",
        "m9 <- glm(data=df[df$colexifies ==1, ], \n",
        "          maintained ~ Ontological_pairs, \n",
        "          family='binomial')\n",
        "\n",
        "#best model(in terms of AIC)\n",
        "\n",
        "m10 <- glm(formula = maintained ~ phonetic_pairs + cosine_sim + path_pairs + \n",
        "    wup_pairs + Semantic_pairs + Ontological_pairs, \n",
        "    family = \"binomial\", \n",
        "    data = df[df$colexifies == 1, ])\n",
        "\n",
        "print('ALL FEATURES')\n",
        "print(summary(m1))\n",
        "print('INDIVIDUAL MODELS')\n",
        "print(summary(m2))\n",
        "print(summary(m3))\n",
        "print(summary(m4))\n",
        "print(summary(m5))\n",
        "print(summary(m6))\n",
        "print(summary(m7))\n",
        "print(summary(m8))\n",
        "print(summary(m9))\n",
        "print('BEST MODEL')\n",
        "print(summary(m10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yd2TaLd0HAqQ"
      },
      "source": [
        "Now for the best model, train and test it 10 times to check for accuracy and robustness of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5kydCb4G3Ip",
        "outputId": "be5a39e3-d5e7-414f-cce1-44341bc5783c"
      },
      "source": [
        "#multiple models at once\n",
        "import random\n",
        "import sklearn\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "#set random seed\n",
        "random.seed(10)\n",
        "#fit the model with the wanted features\n",
        "model = LogisticRegression()\n",
        "supp_df = df.dropna()\n",
        "x = supp_df[['phonetic_pairs' , 'cosine_sim' , 'path_pairs' , \n",
        "    'wup_pairs' , 'Semantic_pairs' , 'Ontological_pairs']]\n",
        "y = supp_df['maintained']\n",
        "model.fit(x, y)\n",
        "supp_df['log_reg_prediction'] = model.predict(x)\n",
        "#now lets set several train-test sets (in this case 10) to acquire a more robust model\n",
        "#this way we ensure the result is not just because of the data set in the train or test model\n",
        "accuracies = []\n",
        "for i in range(10):\n",
        "  data_train, data_test = sklearn.model_selection.train_test_split(supp_df) # defalut is 20/80\n",
        "  x_train = data_train[['phonetic_pairs' , 'cosine_sim' , 'path_pairs' , \n",
        "    'wup_pairs' , 'Semantic_pairs' , 'Ontological_pairs']]\n",
        "  y_train = data_train['maintained']\n",
        "  x_test = data_test[['phonetic_pairs' , 'cosine_sim' , 'path_pairs' , \n",
        "    'wup_pairs' , 'Semantic_pairs' , 'Ontological_pairs']]\n",
        "  y_test = data_test['maintained']\n",
        "  accuracies.append(model.score(x_test, y_test))\n",
        "print(accuracies)\n",
        "#mean of all the accuracies\n",
        "print(sum(accuracies)/10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.780327868852459, 0.8, 0.7901639344262295, 0.8262295081967214, 0.780327868852459, 0.8229508196721311, 0.8360655737704918, 0.8, 0.8163934426229508, 0.7967213114754098]\n",
            "0.8049180327868852\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  from ipykernel import kernelapp as app\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NpN_pDMLlmZ"
      },
      "source": [
        "2.2 Check for crosslinguistic heterogeneity\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uo1FSnoTL-aD",
        "outputId": "536ec889-88cc-466f-cdba-9de0532ad782"
      },
      "source": [
        "%%R\n",
        "clm1 <- glm(data=df[df$colexifies ==1, ], \n",
        "          maintained ~ Family+phonetic_pairs+cosine_sim +n_char+pos_same+path_pairs+wup_pairs+ \n",
        "            Semantic_pairs+Ontological_pairs,\n",
        "          family='binomial')\n",
        "print(summary(clm1))\n",
        "\n",
        "clm2 <- glm(data=df[df$colexifies ==1, ], \n",
        "          maintained~Family,\n",
        "          family='binomial')\n",
        "print(summary(clm2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Call:\n",
            "glm(formula = maintained ~ Family + phonetic_pairs + cosine_sim + \n",
            "    n_char + pos_same + path_pairs + wup_pairs + Semantic_pairs + \n",
            "    Ontological_pairs, family = \"binomial\", data = df[df$colexifies == \n",
            "    1, ])\n",
            "\n",
            "Deviance Residuals: \n",
            "    Min       1Q   Median       3Q      Max  \n",
            "-3.2185  -0.6933   0.2190   0.6736   2.9576  \n",
            "\n",
            "Coefficients:\n",
            "                    Estimate Std. Error z value Pr(>|z|)    \n",
            "(Intercept)         -1.36883    0.40343  -3.393 0.000691 ***\n",
            "FamilyIndo-European  0.09884    0.17607   0.561 0.574533    \n",
            "phonetic_pairs      -0.74017    0.08747  -8.462  < 2e-16 ***\n",
            "cosine_sim           7.03741    0.61139  11.511  < 2e-16 ***\n",
            "n_char              -0.02584    0.04698  -0.550 0.582322    \n",
            "pos_same1            0.04699    0.32600   0.144 0.885390    \n",
            "path_pairs           4.63146    1.88200   2.461 0.013858 *  \n",
            "wup_pairs           -2.89712    0.82136  -3.527 0.000420 ***\n",
            "Semantic_pairs1      0.58966    0.17649   3.341 0.000835 ***\n",
            "Ontological_pairs1   0.34554    0.20422   1.692 0.090647 .  \n",
            "---\n",
            "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
            "\n",
            "(Dispersion parameter for binomial family taken to be 1)\n",
            "\n",
            "    Null deviance: 1690.3  on 1219  degrees of freedom\n",
            "Residual deviance: 1102.9  on 1210  degrees of freedom\n",
            "  (609 observations deleted due to missingness)\n",
            "AIC: 1122.9\n",
            "\n",
            "Number of Fisher Scoring iterations: 5\n",
            "\n",
            "\n",
            "Call:\n",
            "glm(formula = maintained ~ Family, family = \"binomial\", data = df[df$colexifies == \n",
            "    1, ])\n",
            "\n",
            "Deviance Residuals: \n",
            "    Min       1Q   Median       3Q      Max  \n",
            "-1.4472  -0.8866  -0.8866   0.9297   1.4993  \n",
            "\n",
            "Coefficients:\n",
            "                    Estimate Std. Error z value Pr(>|z|)    \n",
            "(Intercept)         -0.73089    0.07197  -10.15   <2e-16 ***\n",
            "FamilyIndo-European  1.34599    0.09903   13.59   <2e-16 ***\n",
            "---\n",
            "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
            "\n",
            "(Dispersion parameter for binomial family taken to be 1)\n",
            "\n",
            "    Null deviance: 2535.2  on 1828  degrees of freedom\n",
            "Residual deviance: 2339.7  on 1827  degrees of freedom\n",
            "AIC: 2343.7\n",
            "\n",
            "Number of Fisher Scoring iterations: 4\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpyXIpnlM2Wb"
      },
      "source": [
        "# 3. QUALITATIVE ANALYSIS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rg8cK03ANh-W"
      },
      "source": [
        "plots for every feature with percentages comparing loss/maintained and between linguistic families to further analyse what happens to colexifications trough time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzMNg2EaM6th"
      },
      "source": [
        "%%R\n",
        "#quantitative analysis\n",
        "#first select just the attested colexifications and split the df into polynesian and romance\n",
        "attested_colex = df[df$colexifies ==1, ]\n",
        "pol_att = attested_colex[attested_colex$Family=='Indo-European',]\n",
        "rom_att = attested_colex[attested_colex$Family=='Proto Polynesian',]\n",
        "\n",
        "#turn count data into proportions for a better comparison\n",
        "#change DF, var1 and var2 and title parameters to the chosen ones\n",
        "counts <- table(DF$var1, DF$var2, dnn=c(var1, var2))\n",
        "props <- (prop.table(counts,2))\n",
        "props <- as.data.frame(props)\n",
        "#plot the data\n",
        "ggplot(props, aes(x=var1, y=Freq, fill=var2)) + \n",
        "  geom_col(position='dodge') +\n",
        "  ggtitle('title')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}